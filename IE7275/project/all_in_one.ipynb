{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE7275 Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    "- Anqi Guo\n",
    "- Junxiang Yang\n",
    "- Lingxuan Ye"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "All codes are compatible and robust (hope so) in Google Colab environment, while I believe it is of necessity to specify the local environment we test in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPython Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import version, version_info\n",
    "with open('environment.md', 'w') as f:\n",
    "    f.write(\n",
    "        '# Environment\\n\\n'\n",
    "        '## CPython Version\\n\\n'\n",
    "        f'{version}\\n\\n'\n",
    "        '## Venv Requirements\\n\\n'\n",
    "        '```\\n'\n",
    "    )\n",
    "version_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venv Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze && pip freeze >> environment.md\n",
    "with open('environment.md', 'a') as f:\n",
    "    f.write('```\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "from typing import (Any, Callable, Dict, Iterable, Iterator, Literal,\n",
    "                    NamedTuple, Optional, TypeVar, Union, overload)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `Self` is not supported until Python 3.11\n",
    "# return `self` for method chaining\n",
    "Self = TypeVar('Self', bound='Magic')  # type: ignore # Stupid Pylance\n",
    "Estimator = Any\n",
    "\n",
    "PARAMS = {\n",
    "    'estimator': [\n",
    "        GaussianNB,\n",
    "        KNeighborsClassifier,\n",
    "        LinearDiscriminantAnalysis,\n",
    "        SVC,\n",
    "        DecisionTreeClassifier\n",
    "    ],\n",
    "    'dropna': [True, False],\n",
    "    'numerify': [True, False],\n",
    "    'numerify_by': ['codes', 'one-hot'],\n",
    "    'normalize': [True, False],\n",
    "    'normalize_by': ['std', 'max-min'],\n",
    "    'pca': [True, False]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Type(Enum):\n",
    "    TRUE_POSITIVE = auto()\n",
    "    FALSE_POSITIVE = auto()\n",
    "    FALSE_NEGATIVE = auto()\n",
    "    TRUE_NEGATIVE = auto()\n",
    "    NON_BINARY_SAME = auto()\n",
    "    NON_BINARY_DIFF = auto()\n",
    "\n",
    "\n",
    "TP = Type.TRUE_POSITIVE\n",
    "FP = Type.FALSE_POSITIVE\n",
    "FN = Type.FALSE_NEGATIVE\n",
    "TN = Type.TRUE_NEGATIVE\n",
    "NS = Type.NON_BINARY_SAME\n",
    "ND = Type.NON_BINARY_DIFF\n",
    "\n",
    "\n",
    "class TruthPair:\n",
    "\n",
    "    predicted: Any\n",
    "    actual: Any\n",
    "\n",
    "    def __init__(self, predicted: Any, actual: Any) -> None:\n",
    "        self.predicted = predicted\n",
    "        self.actual = actual\n",
    "\n",
    "    @property\n",
    "    def type_(self) -> Type:\n",
    "        if self.predicted == self.actual:\n",
    "            return NS\n",
    "        else:\n",
    "            return ND\n",
    "\n",
    "\n",
    "class BoolTruthPair(TruthPair):\n",
    "\n",
    "    predicted: bool\n",
    "    actual: bool\n",
    "\n",
    "    def __init__(self, predicted: bool, actual: bool) -> None:\n",
    "        if not isinstance(predicted, bool):\n",
    "            predicted = bool(predicted)\n",
    "        if not isinstance(actual, bool):\n",
    "            actual = bool(actual)\n",
    "        super().__init__(predicted, actual)\n",
    "\n",
    "    @property\n",
    "    def type_(self) -> Type:\n",
    "        if self.predicted:\n",
    "            return TP if self.actual else FP\n",
    "        else:\n",
    "            return FN if self.actual else TN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatix:\n",
    "\n",
    "    __is_binary: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterable: Optional[Iterable[Type]] = None,\n",
    "        *,\n",
    "        count_tp: int = 0,\n",
    "        count_fp: int = 0,\n",
    "        count_fn: int = 0,\n",
    "        count_tn: int = 0\n",
    "    ) -> None:\n",
    "        self.__count: Counter = Counter({\n",
    "            TP: count_tp,\n",
    "            FP: count_fp,\n",
    "            FN: count_fn,\n",
    "            TN: count_tn\n",
    "        })\n",
    "        if iterable is not None:\n",
    "            if isinstance(iterable, Iterator):\n",
    "                iterable = list(iterable)   # !!!\n",
    "            self.__sanity_check(iterable)\n",
    "            self.__count.update(iterable)\n",
    "\n",
    "    def __sanity_check(self, iterable: Iterable[Type]) -> None:\n",
    "        for i in iterable:\n",
    "            if not isinstance(i, Type):\n",
    "                raise TypeError(\n",
    "                    'value in argument `iterable` must be '\n",
    "                    'instance of `Type`'\n",
    "                )\n",
    "            if i in (NS, ND) and self.__is_binary:\n",
    "                self.__is_binary = False\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.__count.clear()\n",
    "\n",
    "    reset = clear\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        iterable: Optional[Iterable[Type]] = None,\n",
    "        *,\n",
    "        count_tp: int = 0,\n",
    "        count_fp: int = 0,\n",
    "        count_fn: int = 0,\n",
    "        count_tn: int = 0\n",
    "    ) -> None:\n",
    "        self.__count[TP] += count_tp\n",
    "        self.__count[FP] += count_fp\n",
    "        self.__count[FN] += count_fn\n",
    "        self.__count[TN] += count_tn\n",
    "        if iterable is not None:\n",
    "            if isinstance(iterable, Iterator):\n",
    "                iterable = list(iterable)\n",
    "            self.__sanity_check(iterable)\n",
    "            self.__count.update(iterable)\n",
    "\n",
    "    @property\n",
    "    def matrix(self) -> pd.DataFrame:\n",
    "        assert self.__is_binary\n",
    "        matrix = pd.DataFrame(\n",
    "            index=['Predicted Positive', 'Predicted Negative'],\n",
    "            columns=['Actual Positive', 'Actual Negative']\n",
    "        )\n",
    "        matrix.iloc[0, 0] = self.__count[TP]\n",
    "        matrix.iloc[0, 1] = self.__count[FP]\n",
    "        matrix.iloc[1, 0] = self.__count[FN]\n",
    "        matrix.iloc[1, 1] = self.__count[TN]\n",
    "        return matrix\n",
    "\n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        \"\"\"\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "        Return NaN for `ZeroDivisionError`.\n",
    "\n",
    "        This property assumes that attribute `__count` only contains keys\n",
    "        specified in method `__init__`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.__is_binary:\n",
    "                return (\n",
    "                    self.__count[TP] + self.__count[TN]\n",
    "                ) / self.__count.total()\n",
    "            else:\n",
    "                return (\n",
    "                    self.__count[TP] + self.__count[TN] + self.__count[NS]\n",
    "                ) / self.__count.total()\n",
    "        except ZeroDivisionError:\n",
    "            return float('nan')\n",
    "\n",
    "    ACC = accuracy\n",
    "\n",
    "    @property\n",
    "    def sensitivity(self) -> float:\n",
    "        \"\"\"\n",
    "        sensitivity = TP / (TP + FN)\n",
    "\n",
    "        Return NaN for `ZeroDivisionError`.\n",
    "        \"\"\"\n",
    "        assert self.__is_binary\n",
    "        try:\n",
    "            return self.__count[TP] / (self.__count[TP] + self.__count[FN])\n",
    "        except ZeroDivisionError:\n",
    "            return float('nan')\n",
    "\n",
    "    recall = hit_rate = true_positive_rate = TPR = sensitivity\n",
    "\n",
    "    @property\n",
    "    def specificity(self) -> float:\n",
    "        \"\"\"\n",
    "        specificity = TN / (TN + FP)\n",
    "\n",
    "        Return NaN for `ZeroDivisionError`.\n",
    "        \"\"\"\n",
    "        assert self.__is_binary\n",
    "        try:\n",
    "            return self.__count[TN] / (self.__count[TN] + self.__count[FP])\n",
    "        except ZeroDivisionError:\n",
    "            return float('nan')\n",
    "\n",
    "    selectivity = true_negative_rate = TNR = specificity\n",
    "\n",
    "    @property\n",
    "    def F1_score(self) -> float:\n",
    "        \"\"\"\n",
    "        F1_score = 2TP / (2TP + FP + FN)\n",
    "\n",
    "        Return NaN for `ZeroDivisionError`.\n",
    "        \"\"\"\n",
    "        assert self.__is_binary\n",
    "        try:\n",
    "            return self.__count[TP] * 2 / (\n",
    "                self.__count[TP] * 2 +\n",
    "                self.__count[FP] +\n",
    "                self.__count[FN]\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            return float('nan')\n",
    "\n",
    "    @property\n",
    "    def statistics(self) -> pd.DataFrame:\n",
    "        if self.__is_binary:\n",
    "            stats = pd.DataFrame({\n",
    "                'accuracy': {\n",
    "                    'alias': 'ACC',\n",
    "                    'formula': '(TP + TN) / (TP + TN + FP + FN)',\n",
    "                    'value': self.accuracy\n",
    "                },\n",
    "                'sensitivity': {\n",
    "                    'alias': 'recall, hit rate, true positive rate, TPR',\n",
    "                    'formula': 'TP / (TP + FN)',\n",
    "                    'value': self.sensitivity\n",
    "                },\n",
    "                'specificity': {\n",
    "                    'alias': 'selectivity, true negative rate, TNR',\n",
    "                    'formula': 'TN / (TN + FP)',\n",
    "                    'value': self.specificity\n",
    "                },\n",
    "                'F1_score': {\n",
    "                    'alias': 'N/A',\n",
    "                    'formula': '2TP / (2TP + FP + FN)',\n",
    "                    'value': self.F1_score\n",
    "                },\n",
    "            }).T\n",
    "        else:\n",
    "            stats = pd.DataFrame({\n",
    "                'accuracy': {\n",
    "                    'alias': 'ACC',\n",
    "                    'formula': 'T / T + F',\n",
    "                    'value': self.accuracy\n",
    "                }\n",
    "            }).T\n",
    "        stats['value'] = stats['value'].apply(pd.to_numeric)\n",
    "        return stats\n",
    "\n",
    "    stats = statistics\n",
    "\n",
    "    def _repr_html_(self) -> str:\n",
    "        try:\n",
    "            matrix_html = self.matrix._repr_html_()\n",
    "        except AssertionError:\n",
    "            matrix_html = 'Not Available.'\n",
    "        stats_html = self.statistics._repr_html_()\n",
    "        return f\"\"\"\n",
    "            <div>\n",
    "                <h4>Confusion Matrix</h4>\n",
    "                    <div>{matrix_html}</div>\n",
    "                <h4>Statistics</h4>\n",
    "                    <div>{stats_html}</div>\n",
    "            </div>\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors, Returns and Miscellany\n",
    "\n",
    "Code cell below defines a custom exception, an argument-passing standard, and two subclasses of NamedTuple for methods to ruturn access-friendly results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Args(NamedTuple):\n",
    "    \"\"\"\n",
    "    Set default value to Mutable is never a good choice,\n",
    "    for example, `kwargs = {}` should never be considered.\n",
    "    \"\"\"\n",
    "    args: tuple = ()\n",
    "    kwargs: Dict[str, Any] = dict()\n",
    "\n",
    "\n",
    "class PCA_Result(NamedTuple):\n",
    "    summary: pd.DataFrame\n",
    "    components: pd.DataFrame\n",
    "    scores: pd.DataFrame\n",
    "\n",
    "\n",
    "class BestResult(NamedTuple):\n",
    "\n",
    "    combinations: np.ndarray[tuple, np.dtype[np.object_]]\n",
    "    scores: np.ndarray[float, np.dtype[np.float_]]\n",
    "\n",
    "    def _repr_html_(self) -> str:\n",
    "        tab = '&nbsp;' * 4\n",
    "        item = '\\n'.join(\n",
    "            f\"\"\"\n",
    "            <li>\n",
    "            <p><b>Parameters</b></p>\n",
    "            <p>{tab}Estimator type: {j[0].__name__}, Drop NaN: {j[1]}</p>\n",
    "            <p>{tab}Convert categoricals: {j[2]}, Convert by: {j[3]}</p>\n",
    "            <p>{tab}Normalize data: {j[4]}, Normalize by: {j[5]}</p>\n",
    "            <p>{tab}PCA-Decomposite: {j[6]}</p>\n",
    "            <p><b>Accuracy</b></p>\n",
    "            <p>{tab}{self.scores[i]}</p>\n",
    "            </li>\n",
    "            \"\"\"\n",
    "            for i, j in enumerate(self.combinations)\n",
    "        )\n",
    "        return f\"\"\"\n",
    "            <h2>Top-{len(self.combinations)} Conbinations</h2>\n",
    "                <ol>\n",
    "                    {item}\n",
    "                </ol>\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Magic!\n",
    "\n",
    "Code cell below is the most important part of our project. It encapsulates data retrieving, data preprocessing and modeling processes and provides simple and concise APIs for user calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Magic:\n",
    "\n",
    "    read_from: Optional[Path]\n",
    "    y_label: str\n",
    "\n",
    "    __raw: pd.DataFrame\n",
    "    __y: pd.Series\n",
    "    __positive: Optional[str]\n",
    "    __data: pd.DataFrame\n",
    "    __estimator: Optional[Estimator] = None\n",
    "    __cache: Optional[pd.DataFrame] = None\n",
    "\n",
    "    @overload\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Path,\n",
    "        y_label: str,\n",
    "        positive: Optional[str],\n",
    "        estimator: Optional[Estimator],\n",
    "        *,\n",
    "        read_args: Optional[Args],\n",
    "        preprocess_args: Optional[Args]\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    @overload\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: str,\n",
    "        y_label: str,\n",
    "        positive: Optional[str],\n",
    "        estimator: Optional[Estimator],\n",
    "        *,\n",
    "        read_args: Optional[Args],\n",
    "        preprocess_args: Optional[Args]\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    @overload\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: pd.DataFrame,\n",
    "        y_label: str,\n",
    "        positive: Optional[str],\n",
    "        estimator: Optional[Estimator],\n",
    "        *,\n",
    "        read_args: Optional[Args],\n",
    "        preprocess_args: Optional[Args]\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        y_label,\n",
    "        positive=None,\n",
    "        estimator=None,\n",
    "        *,\n",
    "        read_args=None,\n",
    "        preprocess_args=None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : Path | str | pd.DataFrame\n",
    "            Dataset source.\n",
    "        y_label : str\n",
    "            Determine which column is classification objective.\n",
    "        positive : Optional[str], optional\n",
    "            Mark specified class as positive.\n",
    "        estimator : Estimator\n",
    "            Estimator instance.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError\n",
    "            _description_\n",
    "        Please carefully read `self.read.__doc__`\n",
    "        and `self.preprocess.__doc__`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        - A complete read_args should be like this:\n",
    "\n",
    "            ```\n",
    "            Args(\n",
    "                args=(),\n",
    "                kwargs={\n",
    "                    'func': None,\n",
    "                    'func_args': Args()\n",
    "                }\n",
    "            )\n",
    "            ```\n",
    "\n",
    "        - A complete preprocess_args should be like this:\n",
    "\n",
    "            ```\n",
    "            Args(\n",
    "                args=(),\n",
    "                kwargs={\n",
    "                    'dropna': True,\n",
    "                    'dropna_args': Args(),\n",
    "                    'numerify': True,\n",
    "                    'numerify_args': Args(\n",
    "                        args=('codes',),\n",
    "                        kwargs={'func': None, 'func_args': Args()}\n",
    "                    ),\n",
    "                    'normalize': True,\n",
    "                    'normalize_args': Args(\n",
    "                        args=('std',)\n",
    "                        kwargs={'func': None, 'func_args': Args()}\n",
    "                    ),\n",
    "                    'pca': True,\n",
    "                    'pca_args': Args(\n",
    "                        args=(0.85, ),\n",
    "                        kwargs={}\n",
    "                    ),\n",
    "                    'func': None,\n",
    "                    'func_args': Args()\n",
    "                }\n",
    "            )\n",
    "            ```\n",
    "\n",
    "        Fortunately, the most arguments of member methods have been set to\n",
    "        proper values by default.\n",
    "\n",
    "        Further, this incredible module has provided the function `warp_args`\n",
    "        to warp the flat argument array passed in.\n",
    "        \"\"\"\n",
    "        self.y_label = y_label\n",
    "        self.__estimator = estimator\n",
    "        if read_args is None:\n",
    "            read_args = Args()\n",
    "        if preprocess_args is None:\n",
    "            preprocess_args = Args()\n",
    "        if isinstance(dataset, str):\n",
    "            dataset = Path(dataset)\n",
    "        if isinstance(dataset, Path):\n",
    "            self.read_from = dataset\n",
    "            self.read(*read_args.args, **read_args.kwargs)\n",
    "            self.preprocess(*preprocess_args.args, **preprocess_args.kwargs)\n",
    "        elif isinstance(dataset, pd.DataFrame):\n",
    "            self.read_from = None\n",
    "            self.__raw = dataset\n",
    "            self.preprocess(*preprocess_args.args, **preprocess_args.kwargs)\n",
    "        else:\n",
    "            raise TypeError('Invalid type for argument `dataset`.')\n",
    "        self.positive = positive\n",
    "\n",
    "    def read(\n",
    "        self: Self,\n",
    "        *,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        HTML file may have an unpredictable structure, therefore, to make\n",
    "        this method more concise, reading HTML is required to be implemented\n",
    "        from outer scope.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        func : Callable[..., pd.DataFrame], optional\n",
    "            If not None, the Callable passed in will be called for\n",
    "            the data retrieving.\n",
    "        func_args : Args, optional\n",
    "            Arguments for `func`.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FormatError\n",
    "            Raise when file extension is invalid.\n",
    "        \"\"\"\n",
    "        if func is not None:\n",
    "            if func_args is None:\n",
    "                func_args = Args()\n",
    "            self.__raw = func(*func_args.args, **func_args.kwargs)\n",
    "            return self\n",
    "        assert self.read_from is not None\n",
    "        extension: str = self.read_from.suffix.lower().lstrip('.')\n",
    "        if extension == 'csv':\n",
    "            self.__raw = pd.read_csv(self.read_from)\n",
    "        elif extension == 'json':\n",
    "            self.__raw = pd.read_json(self.read_from)\n",
    "        elif extension  == 'xml':\n",
    "            self.__raw = pd.read_xml(self.read_from)\n",
    "        elif extension in ('xlsx', 'xls'):\n",
    "            self.__raw = pd.read_excel(self.read_from)\n",
    "        else:\n",
    "            raise FormatError('Unknown dataset format.')\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def numerify(\n",
    "        data: pd.DataFrame,\n",
    "        by: Literal['codes', 'one-hot'] = 'codes',\n",
    "        *,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert categorical variables into numerical variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data with categorical variables.\n",
    "        by : Literal['codes', 'one-hot'], optional\n",
    "                'codes' : Convert with `.cat.codes`.\n",
    "                'one-hot' : Convert with `pd.get_dummies`.\n",
    "            Determine how to convert categorical variables to numerical.\n",
    "        func : Callable[..., pd.DataFrame], optional\n",
    "            If not None, argument `by` will be omitted, and the Callable\n",
    "            passed in will be called for the conversion.\n",
    "        func_args : Args, optional\n",
    "            Arguments for `func`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Data that all variables are numerical.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Raise when the value of argument `by` is invalid.\n",
    "        \"\"\"\n",
    "        if func is not None:\n",
    "            if func_args is None:\n",
    "                func_args = Args()\n",
    "            return func(*func_args.args, **func_args.kwargs)\n",
    "        if by == 'codes':\n",
    "            cat = data.select_dtypes(exclude='number')\n",
    "            return data.assign(**{\n",
    "                label: pd.Categorical(col).codes\n",
    "                for label, col in cat.items()  # `iteritems` is deprecated\n",
    "            })\n",
    "        elif by == 'one-hot':\n",
    "            return pd.get_dummies(data)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for argument `by`.\")\n",
    "\n",
    "    def __numerify(\n",
    "        self: Self,\n",
    "        by: Literal['codes', 'one-hot'] = 'codes',\n",
    "        *,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> Self:\n",
    "        assert self.__cache is not None\n",
    "        self.__cache = self.numerify(\n",
    "            self.__cache,\n",
    "            by,\n",
    "            func=func,\n",
    "            func_args=func_args\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(\n",
    "        data: pd.DataFrame,\n",
    "        by: Literal['std', 'max-min'] = 'std',\n",
    "        *,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Normalize data.\n",
    "\n",
    "        Note that data passed in is assumed to be with no NaN value.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data with categorical variables.\n",
    "        by : Literal['std', 'max-min'], optional\n",
    "                'std' : Standardization.\n",
    "                'max-min' : Max-Min Normalization.\n",
    "            Normalization type.\n",
    "        func : Callable[..., pd.DataFrame], optional\n",
    "            If not None, argument `by` will be omitted, and the Callable\n",
    "            passed in will be called for the normalization.\n",
    "        func_args : Args, optional\n",
    "            Arguments for `func`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Normalized data.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Raise when the value of argument `by` is invalid.\n",
    "        \"\"\"\n",
    "        if func is not None:\n",
    "            if func_args is None:\n",
    "                func_args = Args()\n",
    "            return func(*func_args.args, **func_args.kwargs)\n",
    "        num = data.select_dtypes(include='number')\n",
    "        if by == 'std':\n",
    "            num = (num - num.mean()) / num.std()\n",
    "        elif by == 'max-min':\n",
    "            num = (num - num.min()) / (num.max() - num.min())\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for argument `by`.\")\n",
    "        return data.assign(**dict(num.items()))\n",
    "\n",
    "    def __normalize(\n",
    "        self: Self,\n",
    "        by: Literal['std', 'max-min'] = 'std',\n",
    "        *,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> Self:\n",
    "        assert self.__cache is not None\n",
    "        self.__cache = self.normalize(\n",
    "            self.__cache,\n",
    "            by,\n",
    "            func=func,\n",
    "            func_args=func_args\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def pca(data: pd.DataFrame, info_ratio: float = 0.85) -> PCA_Result:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data to be PCA decomposited.\n",
    "        info_ratio : float, optional\n",
    "            PCA info ratio.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        PCA_Result\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        assert 0 <= info_ratio <= 1\n",
    "\n",
    "        pca = PCA()\n",
    "        pca.fit(data)\n",
    "        summary = pd.DataFrame({\n",
    "            'Standard deviation': np.sqrt(pca.explained_variance_),\n",
    "            'Proportion of variance': pca.explained_variance_ratio_,\n",
    "            'Cumulative proportion': np.cumsum(pca.explained_variance_ratio_)\n",
    "        }).T\n",
    "        summary.columns = (f'PC_{i + 1}' for i in range(summary.shape[1]))\n",
    "        for i, j in enumerate(summary.loc['Cumulative proportion']):\n",
    "            if j >= info_ratio:\n",
    "                num_of_pc = i + 1\n",
    "                break\n",
    "        components = pd.DataFrame(\n",
    "            pca.components_.T,\n",
    "            columns=summary.columns,\n",
    "            index=data.columns\n",
    "        ).iloc[:, :num_of_pc]\n",
    "        scores = pd.DataFrame(\n",
    "            pca.transform(data),\n",
    "            columns=summary.columns\n",
    "        ).iloc[:, :num_of_pc]\n",
    "        summary.round(4)\n",
    "        return PCA_Result(summary, components, scores)\n",
    "\n",
    "    def __pca(self: Self, info_ratio: float = 0.85) -> Self:\n",
    "        assert self.__cache is not None\n",
    "        self.__cache = self.pca(self.__cache, info_ratio).scores\n",
    "        return self\n",
    "\n",
    "    def preprocess(\n",
    "        self: Self,\n",
    "        *,\n",
    "        dropna: bool = True,\n",
    "        dropna_args: Optional[Args] = None,\n",
    "        numerify: bool = True,\n",
    "        numerify_args: Optional[Args] = None,\n",
    "        normalize: bool = False,\n",
    "        normalize_args: Optional[Args] = None,\n",
    "        pca: bool = False,\n",
    "        pca_args: Optional[Args] = None,\n",
    "        func: Optional[Callable[..., pd.DataFrame]] = None,\n",
    "        func_args: Optional[Args] = None\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Data prepocessing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dropna : bool, optional\n",
    "            If True, drop rows with NaN value.\n",
    "        dropna_args : Optional[Args], optional\n",
    "            Arguments for `pd.Dataframe.dropna`.\n",
    "        numerify : bool, optional\n",
    "            If True, convert categorical variables to numerical.\n",
    "        numerify_args : Optional[Args], optional\n",
    "            Arguments for `self.__numerify`.\n",
    "        normalize : bool, optional\n",
    "            If True, normalize data.\n",
    "        normalize_args : Optional[Args], optional\n",
    "            Arguments for `self.__normalize`.\n",
    "        pca : bool, optional\n",
    "            If True, PCA-decomposite data.\n",
    "        pca_args : Optional[Args], optional\n",
    "            Arguments for `self.__pca`.\n",
    "        func : Optional[Callable[..., pd.DataFrame]], optional\n",
    "            If not None, all other arguments except `func_args` will be\n",
    "            omitted, and the Callable passed in will be called for\n",
    "            preprocessing.\n",
    "        func_args : Optional[Args], optional\n",
    "            Arguments for `func`.\n",
    "        \"\"\"\n",
    "        if func is not None:\n",
    "            if func_args is None:\n",
    "                func_args = Args()\n",
    "            self.__data = func(*func_args.args, **func_args.kwargs)\n",
    "            return self\n",
    "\n",
    "        self.__cache = self.__raw.copy(deep=True)\n",
    "\n",
    "        if dropna:\n",
    "            if dropna_args is None:\n",
    "                dropna_args = Args()\n",
    "            temp = self.__cache.dropna(*dropna_args.args, **dropna_args.kwargs)\n",
    "            if temp is not None:  # inplace == False\n",
    "                self.__cache = temp\n",
    "\n",
    "        self.__y = self.__cache[self.y_label].astype(str)\n",
    "        self.__cache.drop(self.y_label, axis=1, inplace=True)\n",
    "\n",
    "        if numerify:\n",
    "            if numerify_args is None:\n",
    "                numerify_args = Args()\n",
    "            self.__numerify(*numerify_args.args, **numerify_args.kwargs)\n",
    "\n",
    "        if normalize:\n",
    "            if normalize_args is None:\n",
    "                normalize_args = Args()\n",
    "            self.__normalize(*normalize_args.args, **normalize_args.kwargs)\n",
    "\n",
    "        if pca:\n",
    "            if pca_args is None:\n",
    "                pca_args = Args()\n",
    "            self.__pca(*pca_args.args, **pca_args.kwargs)\n",
    "\n",
    "        self.__data = self.__cache.copy(deep=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def raw(self) -> pd.DataFrame:\n",
    "        return self.__raw\n",
    "\n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        return self.__data\n",
    "\n",
    "    @property\n",
    "    def y(self) -> pd.Series:\n",
    "        return self.__y\n",
    "\n",
    "    @property\n",
    "    def y_cat(self) -> pd.Categorical:\n",
    "        return pd.Categorical(self.__y)\n",
    "\n",
    "    @property\n",
    "    def y_num(self) -> np.ndarray:\n",
    "        return self.y_cat.codes\n",
    "\n",
    "    @property\n",
    "    def is_binary(self) -> bool:\n",
    "        return True if len(self.__y.unique()) <= 2 else False\n",
    "\n",
    "    @property\n",
    "    def positive(self) ->Optional[str]:\n",
    "        \"\"\"Return class marked positive.\"\"\"\n",
    "        return self.__positive\n",
    "\n",
    "    @positive.setter\n",
    "    def positive(self, __value: Optional[str]) -> None:\n",
    "        assert __value in self.__y.to_numpy() or __value is None\n",
    "        self.__positive = __value\n",
    "\n",
    "    @property\n",
    "    def estimator(self) -> Estimator:\n",
    "        return self.__estimator\n",
    "\n",
    "    @estimator.setter\n",
    "    def estimator(self, __value: Estimator) -> None:\n",
    "        if self.__estimator is not None:\n",
    "            input_ = input(\n",
    "                f'Existing estimator `{self.__estimator}` will be destructed, '\n",
    "                'this process is irreversible!\\n'\n",
    "                'Press `Y` + `Enter` to continue.\\n'\n",
    "                'Press any key else to stop.\\n'\n",
    "            )\n",
    "            if input_.lower() != 'y':\n",
    "                return print('Assigning process terminated.')\n",
    "        self.__estimator = __value\n",
    "        return print(f'Property `estimator` is now set to `{__value}`.')\n",
    "\n",
    "    def show_doc(self, member: Optional[str] = None) -> None:\n",
    "        if member is None:\n",
    "            return print(self.__estimator.__doc__)\n",
    "        return print(getattr(self.__estimator, member).__doc__)\n",
    "\n",
    "    @overload\n",
    "    @staticmethod\n",
    "    def fit(\n",
    "        X: pd.DataFrame,\n",
    "        y: np.ndarray,\n",
    "        estimator: Estimator,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    @overload\n",
    "    @staticmethod\n",
    "    def fit(\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.Series,\n",
    "        estimator: Estimator,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(X, y, estimator: Estimator, *args, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Fit data with given estimator instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Training data.\n",
    "        y : np.ndarray | pd.Series\n",
    "            Classes corresponding to training data.\n",
    "        \"\"\"\n",
    "        estimator.fit(X, y, *args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(\n",
    "        X: pd.DataFrame,\n",
    "        estimator: Estimator,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict data with given estimator instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Testing data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Classes predicted.\n",
    "        \"\"\"\n",
    "        return estimator.predict(X, *args, **kwargs)\n",
    "\n",
    "    def __results(self, y_pred: Iterable, y_test: Iterable):\n",
    "        iter_pred = iter(y_pred)\n",
    "        iter_test = iter(y_test)\n",
    "        is_binary = self.is_binary\n",
    "        while True:\n",
    "            try:\n",
    "                pred = next(iter_pred)\n",
    "                test = next(iter_test)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            if is_binary:\n",
    "                assert self.__positive is not None\n",
    "                yield BoolTruthPair(\n",
    "                    (pred == self.__positive),\n",
    "                    (test == self.__positive)\n",
    "                ).type_\n",
    "            else:\n",
    "                yield TruthPair(pred, test).type_\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        test_size: float = 0.2,\n",
    "        *,\n",
    "        fit_args: Optional[Args] = None,\n",
    "        predict_args: Optional[Args] = None,\n",
    "        verbose: bool = True,\n",
    "        return_: bool = False\n",
    "    ) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Evaluate `self.__estimator` performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_size : float, optional\n",
    "            Size of test set.\n",
    "            See more in: 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split'\n",
    "        fit_args : Args, optional\n",
    "            Arguments for `self.fit`.\n",
    "        predict_args : Args, optional\n",
    "            Arguments for `self.predict`.\n",
    "        verbose : bool, optional\n",
    "            If True, display details.\n",
    "        return_ : bool, optional\n",
    "            If True, return accuracy.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[float] :\n",
    "            Accuracy.\n",
    "        \"\"\"\n",
    "        assert self.__estimator is not None\n",
    "        assert 0 < test_size < 1\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            self.__data,\n",
    "            self.__y\n",
    "            # in current implementation,\n",
    "            # I decide not to use `self.y_cat` and `self.y_num`\n",
    "        )\n",
    "\n",
    "        if fit_args is None:\n",
    "            fit_args = Args()\n",
    "        self.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            self.__estimator,\n",
    "            *fit_args.args,\n",
    "            **fit_args.kwargs\n",
    "        )\n",
    "\n",
    "        if predict_args is None:\n",
    "            predict_args = Args()\n",
    "        y_pred: np.ndarray = self.predict(\n",
    "            x_test,\n",
    "            self.__estimator,\n",
    "            *predict_args.args,\n",
    "            **predict_args.kwargs\n",
    "        )\n",
    "\n",
    "        result = ConfusionMatix(self.__results(y_pred, y_test))\n",
    "\n",
    "        if verbose:\n",
    "            display(result)\n",
    "\n",
    "        return result.accuracy if return_ else None\n",
    "\n",
    "    def kfold_cv(\n",
    "        self,\n",
    "        n_splits: int = 5,\n",
    "        *,\n",
    "        shuffle: bool = False,\n",
    "        random_state: Any = None,\n",
    "        estimator_args: Optional[Args] = None,\n",
    "        fit_args: Optional[Args] = None,\n",
    "        predict_args: Optional[Args] = None,\n",
    "        verbose: bool = True,\n",
    "        return_: bool = False\n",
    "    ) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        K-Fold cross-validation.\n",
    "        See more in: 'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold'\n",
    "\n",
    "        Note that this method will NOT use `self.__estimator` but a set of\n",
    "        new estimators instantiated from `self.__eatimator.__class__` that\n",
    "        are initiated with the same arguments.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator_args : Args, optional\n",
    "            Arguments for `self.__eatimator.__class__.__init__`.\n",
    "        fit_args : Args, optional\n",
    "            Arguments for `self.fit`.\n",
    "        predict_args : Args, optional\n",
    "            Arguments for `self.predict`.\n",
    "        verbose : bool, optional\n",
    "            If True, display details.\n",
    "        return_ : bool, optional\n",
    "            If True, return  average accuracy.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[float] :\n",
    "            Average accuracy.\n",
    "        \"\"\"\n",
    "        assert self.__estimator is not None\n",
    "\n",
    "        if verbose:\n",
    "            display(HTML(f'<h2{n_splits}-Fold Cross-Validationtitle</h2>'))\n",
    "\n",
    "        data = self.__data\n",
    "        kfold = KFold(n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "        if estimator_args is None:\n",
    "            estimator_args = Args()\n",
    "        if fit_args is None:\n",
    "            fit_args = Args()\n",
    "        if predict_args is None:\n",
    "            predict_args = Args()\n",
    "\n",
    "        stats = ConfusionMatix().statistics\n",
    "        stats['value'] = 0  # NaN is infectious\n",
    "        stats.index = 'average ' + stats.index\n",
    "\n",
    "        # every iteration share the same arguments\n",
    "        for i, (train_indices, test_indices) in enumerate(kfold.split(data)):\n",
    "            x_train = data.iloc[train_indices]\n",
    "            x_test = data.iloc[test_indices]\n",
    "            y_train = self.__y[train_indices]\n",
    "            y_test = self.__y[test_indices]\n",
    "            estimator = type(self.__estimator)(\n",
    "                *estimator_args.args,\n",
    "                **estimator_args.kwargs\n",
    "            )\n",
    "            self.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                estimator,\n",
    "                *fit_args.args,\n",
    "                **fit_args.kwargs\n",
    "            )\n",
    "            y_pred: np.ndarray = self.predict(\n",
    "                x_test,\n",
    "                estimator,\n",
    "                *predict_args.args,\n",
    "                **predict_args.kwargs\n",
    "            )\n",
    "            result = ConfusionMatix(self.__results(y_pred, y_test))\n",
    "            if verbose:\n",
    "                display(HTML(f'<h3>Iteration {i + 1}</h3>'))\n",
    "                display(result)\n",
    "            stats['value'] += result.statistics['value'].to_numpy()\n",
    "\n",
    "        stats['value'] /= n_splits\n",
    "\n",
    "        if verbose:\n",
    "            display(HTML('<h3>Summary</h3>'))\n",
    "            display(stats)\n",
    "\n",
    "        return stats.loc['average accuracy', 'value'] if return_ else None\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        *,\n",
    "        fit_args: Optional[Args] = None,\n",
    "        predict_args: Optional[Args] = None,\n",
    "    ) -> float:\n",
    "        return self.kfold_cv(   # type: ignore\n",
    "            fit_args=fit_args,\n",
    "            predict_args=predict_args,\n",
    "            verbose=False,\n",
    "            return_=True\n",
    "        )\n",
    "\n",
    "    def _repr_html_(self) -> str:\n",
    "        if self.read_from is None:\n",
    "            source_info = 'DataFrame directly imported.'\n",
    "        else:\n",
    "            source_info = str(self.read_from.absolute())\n",
    "        if self.__estimator is None:\n",
    "            estimator_info = 'No estimator has been passed.'\n",
    "        else:\n",
    "            doc: str = self.__estimator.__doc__  # annotated for mypy\n",
    "            doc_html = doc.replace('\\n', '<br/>').replace(' ', '&nbsp;')\n",
    "            estimator_info = f\"\"\"\n",
    "                <details>\n",
    "                    <summary>{self.__estimator.__class__.__name__}</summary>\n",
    "                    <p>{doc_html}</p>\n",
    "                </details>\n",
    "            \"\"\"\n",
    "        return f\"\"\"\n",
    "            <div>\n",
    "                <h2>The Incredible Magic Class for IE7275 Project</h2>\n",
    "                    <h3>Team Members</h3>\n",
    "                        <p>\n",
    "                            <span>Anqi Guo</span>,&nbsp;\n",
    "                            <span>Junxiang Yang</span>,&nbsp;\n",
    "                            <span>Lingxuan Ye</span>&nbsp;\n",
    "                        </p>\n",
    "                    <h3>Status</h3>\n",
    "                        <h4>Data Info</h4>\n",
    "                            <p><b>source</b>: {source_info}</p>\n",
    "                            <p><b>y-label</b>: {self.y_label}</p>\n",
    "                        <h4>Raw Data</h4>\n",
    "                            <div>{self.__raw._repr_html_()}</div>\n",
    "                        <h4>Processed Data</h4>\n",
    "                            <div>{self.__data._repr_html_()}</div>\n",
    "                        <h4>Estimator</h4>\n",
    "                            <div>{estimator_info}</div>\n",
    "            </div>\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast Magic\n",
    "\n",
    "Factory function `cast` for class `Magic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(\n",
    "    dataset: Union[Path, str, pd.DataFrame],\n",
    "    y_label: str,\n",
    "    positive: Optional[str] = None,\n",
    "    estimator: Optional[Estimator] = None,\n",
    "    dropna: bool = True,\n",
    "    numerify: bool = True,\n",
    "    numerify_by: Literal['codes', 'one-hot'] = 'codes',\n",
    "    normalize: bool = False,\n",
    "    normalize_by: Literal['std', 'max-min'] = 'std',\n",
    "    pca: bool = False,\n",
    "    info_ratio: float = 0.85,\n",
    ") -> Magic:\n",
    "    \"\"\"\n",
    "    Factory function of `Magic`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Path | str | pd.DataFrame\n",
    "        Dataset source.\n",
    "    y_label : str\n",
    "        Determine which column is classification objective.\n",
    "    positive : Optional[str], optional\n",
    "        Mark specified class as positive.\n",
    "    estimator : Estimator\n",
    "        Estimator instance.\n",
    "    dropna : bool, optional\n",
    "        If True, drop rows with NaN value.\n",
    "    numerify : bool, optional\n",
    "        If True, convert categorical variables to numerical.\n",
    "    numerify_by : Literal['codes', 'one-hot'], optional\n",
    "            'codes' : Convert with `.cat.codes`.\n",
    "            'one-hot' : Convert with `pd.get_dummies`.\n",
    "        Determine how to convert categorical variables to numerical.\n",
    "    normalize : bool, optional\n",
    "        If True, normalize data.\n",
    "    normalize_by : Literal['std', 'max-min'], optional\n",
    "            'std' : Standardization.\n",
    "            'max-min' : Max-Min Normalization.\n",
    "        Normalization type.\n",
    "    pca : bool, optional\n",
    "        If True, PCA-decomposite data.\n",
    "    info_ratio : float, optional\n",
    "        PCA info ratio.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Magic\n",
    "        `Magic` instance.\n",
    "    \"\"\"\n",
    "    return Magic(\n",
    "        dataset,  # type: ignore\n",
    "        y_label,\n",
    "        positive,\n",
    "        estimator,\n",
    "        preprocess_args=Args(\n",
    "            kwargs={\n",
    "                'dropna': dropna,\n",
    "                'numerify': numerify,\n",
    "                'numerify_args': Args(args=(numerify_by,)),\n",
    "                'normalize': normalize,\n",
    "                'normalize_args': Args(args=(normalize_by,)),\n",
    "                'pca': pca,\n",
    "                'pca_args': Args(args=(info_ratio,))\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "This function could be a temporary implementation because last several lines were implemented in a memory-wasting way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(\n",
    "    dataset: Union[Path, str, pd.DataFrame],\n",
    "    y_label: str,\n",
    "    positive: Optional[str] = None,\n",
    "    params: Optional[Dict[str, list]] = None,\n",
    "    top_n: int = 1\n",
    ") -> BestResult:\n",
    "    if params is None:\n",
    "        params = PARAMS\n",
    "    grid = np.meshgrid(*params.values())\n",
    "    combinations  = np.empty_like(grid[0], dtype=np.object_)\n",
    "    scores = np.empty_like(grid[0], dtype=np.float_)\n",
    "    for index, estimator_type in np.ndenumerate(grid[0]):\n",
    "        estimator = estimator_type()\n",
    "        combination = (estimator_type, *(i[index] for i in grid[1:]))\n",
    "        if not any(index):  # (0, 0, ...)\n",
    "            inst = cast(\n",
    "                dataset,\n",
    "                y_label,\n",
    "                positive,\n",
    "                estimator,\n",
    "                *combination[1:]\n",
    "            )\n",
    "            raw = inst.raw  # to save memory and aviod large volume IO\n",
    "        else:\n",
    "            inst = cast(raw, y_label, positive, estimator, *combination[1:])\n",
    "        combinations[index] = combination\n",
    "        scores[index] = inst.score()\n",
    "    top_n = min(top_n, grid[0].size)\n",
    "    top_n_indices = scores.argsort(axis=None)[::-1][:top_n]\n",
    "    return BestResult(\n",
    "        combinations.flatten()[top_n_indices],\n",
    "        scores.flatten()[top_n_indices]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Invoke `BestResult` instance's dunder method `__repr__` and print the returned string.\n",
    "\n",
    "Note that there is no NaN value in our dataset, and that all variables are numerical. In this case, the parameter `dropna`, `numerify` and `numerify_by` have no contribution to the result and should be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    grid_search(\n",
    "        dataset='./data/heart.csv',\n",
    "        y_label='output',\n",
    "        positive='0',\n",
    "        top_n=50\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result, we conclude that whether we normalize data or not, the way how we normalize data, and whether we do PCA-Decomposition, should not be considered to have significant influence to the data fitting. The only parameter that matters to the prediction accuracy is the estimator type.\n",
    "\n",
    "HTML output below shows us one of the best parameter sets. Note that IPython kernel will automatically render HTML outputs by invoking instance's `_repr_html_` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(\n",
    "    dataset='./data/heart.csv',\n",
    "    y_label='output',\n",
    "    positive='0',\n",
    "    top_n=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results\n",
    "\n",
    "In for-loop defined below, we pass instances of all estimator classes in `PARAMS['estimator']` as argument `estimator` in order to compare they prediction accuracy and other statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in PARAMS['estimator']:\n",
    "    display(HTML(f'<h2>{i.__name__}</h2>'))\n",
    "    magic = cast(\n",
    "        dataset='./data/heart.csv',\n",
    "        y_label='output',\n",
    "        positive='0',\n",
    "        estimator=i()\n",
    "    )\n",
    "    magic.evaluate()\n",
    "    magic.kfold_cv()\n",
    "    display(HTML('<hr/>'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63c39743f639f3c46951a03907d4fb53ddc9f1051a7ffa803df088dddd89abd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
